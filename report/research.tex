\section{Research Questions and Scope}

This motivated us to explore alternative ways to represent participants in WVC applications to increase engagement, interactivity, and attention. 

We are set out to build a prototype WVC application to study the perceived effects of eye-contact, gaze, and head orientation in a virtual 3D space to make up the missing aspects from in-person F2F interactions.

`insert research question`

`insert scope of this project`

Our project explores whether adding eye-contact to the current WVC system will enhance the sense of interaction and presence of the users. Conventional WVC services only offer standard visual and audio communication, and they do not support intuitive and personalized eye-contact between users. Therefore, people still prefer face-to-face meetings because of the highly interactive meeting environment [P. Hart].
In distant-learning classes, for example, presenters (e.g. professors, teachers, students) often feel distracted or disengaged when there are no audiovisual feedback coming from the audience. These feedback include eye contact, gaze direction, and other body language cues.

For example, in the Gallery View in Zoom (and other WVC applications), the audience consists of black boxes and name tags, as shown in Figure 1. If the participant has video turned on, the webcam video stream replaces their box. We will refer to the space each participant takes up on the screen as their footprint. Notice that everyone has the same and uniform footprint, regardless if they are paying attention to the meeting or the active participant.

Thus, current systems neglect important cues presenters use to moderate their lecture. The lack of interactivity is one reason why online lectures are less effective than in-person lectures [T. Nygyen]. In one of the first experimental studies [D. Figlio] on the effects of traditional instruction versus online learning, students attend live lectures instead of watching the same lectures online while supplemental materials and instructions were the same. Researchers [D. Figlio] found modest evidence that the traditional format trumps the online format in engagement. Many people also think it is odd to see their faces during conversations, and it is hard to look away — significantly distracts participants during WVCs.

Lastly, some people are camera-shy and do not want to reveal themselves in WVCs. Thus we decide to explore the effect on participation and engagement from using an avatar as an alias instead of  a live video.

The key metrics we want to observe in this project are: participant’s attention, engagement, and the feeling of connectedness. To explore parameters that effect these metrics, we consolidate these ideas into three core research questions (hereafter will be refer to as RQ1, RQ2, and RQ3):

1. Can a person tell if they are being looked at in a WVC and how can 3D avatars be augmented to enhance this experience.
2. Can a person tell if other participants are looking at each ot
3. her in a WVC and how using 3D avatars can be augmented to increase engagement.How does a person’s attention change as the avatars augmented with WVC enables eye-contact and gaze.

We intend to modify design parameters to our prototype user-interface (UI) of our mock WVC program to study the behaviour of participants.
